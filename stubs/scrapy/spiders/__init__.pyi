from scrapy import signals as signals
from scrapy.http import Request as Request
from scrapy.spiders.crawl import CrawlSpider as CrawlSpider, Rule as Rule
from scrapy.spiders.feed import CSVFeedSpider as CSVFeedSpider, XMLFeedSpider as XMLFeedSpider
from scrapy.spiders.sitemap import SitemapSpider as SitemapSpider
from scrapy.utils.deprecate import method_is_overridden as method_is_overridden
from scrapy.utils.trackref import object_ref as object_ref
from scrapy.utils.url import url_is_from_spider as url_is_from_spider
from typing import Any, Optional

class Spider(object_ref):
    name: Optional[str] = ...
    custom_settings: Optional[dict] = ...
    start_urls: Any = ...
    def __init__(self, name: Optional[Any] = ..., **kwargs: Any) -> None: ...
    @property
    def logger(self): ...
    def log(self, message: Any, level: Any = ..., **kw: Any) -> None: ...
    @classmethod
    def from_crawler(cls, crawler: Any, *args: Any, **kwargs: Any): ...
    def start_requests(self) -> None: ...
    def make_requests_from_url(self, url: Any): ...
    def parse(self, response: Any, **kwargs: Any) -> None: ...
    @classmethod
    def update_settings(cls, settings: Any) -> None: ...
    @classmethod
    def handles_request(cls, request: Any): ...
    @staticmethod
    def close(spider: Any, reason: Any): ...
