from scrapy.http import HtmlResponse as HtmlResponse, Request as Request
from scrapy.linkextractors import LinkExtractor as LinkExtractor
from scrapy.spiders import Spider as Spider
from scrapy.utils.spider import iterate_spider_output as iterate_spider_output
from typing import Any, Optional, Sequence

class Rule:
    link_extractor: Any = ...
    callback: Any = ...
    errback: Any = ...
    cb_kwargs: Any = ...
    process_links: Any = ...
    process_request: Any = ...
    follow: Any = ...
    def __init__(self, link_extractor: Optional[Any] = ..., callback: Optional[Any] = ..., cb_kwargs: Optional[Any] = ..., follow: Optional[Any] = ..., process_links: Optional[Any] = ..., process_request: Optional[Any] = ..., errback: Optional[Any] = ...) -> None: ...

class CrawlSpider(Spider):
    rules: Sequence[Rule] = ...
    def __init__(self, *a: Any, **kw: Any) -> None: ...
    def parse_start_url(self, response: Any, **kwargs: Any): ...
    def process_results(self, response: Any, results: Any): ...
    @classmethod
    def from_crawler(cls, crawler: Any, *args: Any, **kwargs: Any): ...
