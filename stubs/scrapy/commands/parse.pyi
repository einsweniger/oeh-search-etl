from scrapy.commands import BaseRunSpiderCommand as BaseRunSpiderCommand
from scrapy.exceptions import UsageError as UsageError
from scrapy.http import Request as Request
from scrapy.utils import display as display
from scrapy.utils.spider import iterate_spider_output as iterate_spider_output, spidercls_for_request as spidercls_for_request
from typing import Any, Optional

logger: Any

class Command(BaseRunSpiderCommand):
    requires_project: bool = ...
    spider: Any = ...
    items: Any = ...
    requests: Any = ...
    first_response: Any = ...
    def syntax(self): ...
    def short_desc(self): ...
    def add_options(self, parser: Any) -> None: ...
    @property
    def max_level(self): ...
    def add_items(self, lvl: Any, new_items: Any) -> None: ...
    def add_requests(self, lvl: Any, new_reqs: Any) -> None: ...
    def print_items(self, lvl: Optional[Any] = ..., colour: bool = ...) -> None: ...
    def print_requests(self, lvl: Optional[Any] = ..., colour: bool = ...) -> None: ...
    def print_results(self, opts: Any) -> None: ...
    def run_callback(self, response: Any, callback: Any, cb_kwargs: Optional[Any] = ...): ...
    def get_callback_from_rules(self, spider: Any, response: Any): ...
    spidercls: Any = ...
    def set_spidercls(self, url: Any, opts: Any) -> None: ...
    pcrawler: Any = ...
    def start_parsing(self, url: Any, opts: Any) -> None: ...
    def prepare_request(self, spider: Any, request: Any, opts: Any): ...
    def process_options(self, args: Any, opts: Any) -> None: ...
    def process_request_meta(self, opts: Any) -> None: ...
    def process_request_cb_kwargs(self, opts: Any) -> None: ...
    def run(self, args: Any, opts: Any) -> None: ...
