from scrapy import signals as signals
from scrapy.core.downloader.tls import openssl_methods as openssl_methods
from scrapy.exceptions import ScrapyDeprecationWarning as ScrapyDeprecationWarning, StopDownload as StopDownload
from scrapy.http import Headers as Headers
from scrapy.responsetypes import responsetypes as responsetypes
from scrapy.utils.misc import create_instance as create_instance, load_object as load_object
from scrapy.utils.python import to_bytes as to_bytes, to_unicode as to_unicode
from twisted.internet import protocol
from twisted.internet.endpoints import TCP4ClientEndpoint
from twisted.web.client import Agent
from typing import Any, Optional

logger: Any

class HTTP11DownloadHandler:
    lazy: bool = ...
    def __init__(self, settings: Any, crawler: Optional[Any] = ...) -> None: ...
    @classmethod
    def from_crawler(cls, crawler: Any): ...
    def download_request(self, request: Any, spider: Any): ...
    def close(self): ...

class TunnelError(Exception): ...

class TunnelingTCP4ClientEndpoint(TCP4ClientEndpoint):
    def __init__(self, reactor: Any, host: Any, port: Any, proxyConf: Any, contextFactory: Any, timeout: int = ..., bindAddress: Optional[Any] = ...) -> None: ...
    def requestTunnel(self, protocol: Any): ...
    def processProxyResponse(self, rcvd_bytes: Any) -> None: ...
    def connectFailed(self, reason: Any) -> None: ...
    def connect(self, protocolFactory: Any): ...

def tunnel_request_data(host: Any, port: Any, proxy_auth_header: Optional[Any] = ...): ...

class TunnelingAgent(Agent):
    def __init__(self, reactor: Any, proxyConf: Any, contextFactory: Optional[Any] = ..., connectTimeout: Optional[Any] = ..., bindAddress: Optional[Any] = ..., pool: Optional[Any] = ...) -> None: ...

class ScrapyProxyAgent(Agent):
    def __init__(self, reactor: Any, proxyURI: Any, connectTimeout: Optional[Any] = ..., bindAddress: Optional[Any] = ..., pool: Optional[Any] = ...) -> None: ...
    def request(self, method: Any, uri: Any, headers: Optional[Any] = ..., bodyProducer: Optional[Any] = ...): ...

class ScrapyAgent:
    def __init__(self, contextFactory: Optional[Any] = ..., connectTimeout: int = ..., bindAddress: Optional[Any] = ..., pool: Optional[Any] = ..., maxsize: int = ..., warnsize: int = ..., fail_on_dataloss: bool = ..., crawler: Optional[Any] = ...) -> None: ...
    def download_request(self, request: Any): ...

class _RequestBodyProducer:
    body: Any = ...
    length: Any = ...
    def __init__(self, body: Any) -> None: ...
    def startProducing(self, consumer: Any): ...
    def pauseProducing(self) -> None: ...
    def stopProducing(self) -> None: ...

class _ResponseReader(protocol.Protocol):
    def __init__(self, finished: Any, txresponse: Any, request: Any, maxsize: Any, warnsize: Any, fail_on_dataloss: Any, crawler: Any) -> None: ...
    def connectionMade(self) -> None: ...
    def dataReceived(self, bodyBytes: Any) -> None: ...
    def connectionLost(self, reason: Any) -> None: ...
