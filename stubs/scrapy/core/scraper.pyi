from scrapy import signals as signals
from scrapy.core.spidermw import SpiderMiddlewareManager as SpiderMiddlewareManager
from scrapy.exceptions import CloseSpider as CloseSpider, DropItem as DropItem, IgnoreRequest as IgnoreRequest
from scrapy.http import Request as Request, Response as Response
from scrapy.utils.defer import defer_fail as defer_fail, defer_succeed as defer_succeed, iter_errback as iter_errback, parallel as parallel
from scrapy.utils.log import failure_to_exc_info as failure_to_exc_info, logformatter_adapter as logformatter_adapter
from scrapy.utils.misc import load_object as load_object, warn_on_generator_with_return_value as warn_on_generator_with_return_value
from scrapy.utils.spider import iterate_spider_output as iterate_spider_output
from typing import Any

logger: Any

class Slot:
    MIN_RESPONSE_SIZE: int = ...
    max_active_size: Any = ...
    queue: Any = ...
    active: Any = ...
    active_size: int = ...
    itemproc_size: int = ...
    closing: Any = ...
    def __init__(self, max_active_size: int = ...) -> None: ...
    def add_response_request(self, response: Any, request: Any): ...
    def next_response_request_deferred(self): ...
    def finish_response(self, response: Any, request: Any) -> None: ...
    def is_idle(self): ...
    def needs_backout(self): ...

class Scraper:
    slot: Any = ...
    spidermw: Any = ...
    itemproc: Any = ...
    concurrent_items: Any = ...
    crawler: Any = ...
    signals: Any = ...
    logformatter: Any = ...
    def __init__(self, crawler: Any) -> None: ...
    def open_spider(self, spider: Any) -> None: ...
    def close_spider(self, spider: Any): ...
    def is_idle(self): ...
    def enqueue_scrape(self, response: Any, request: Any, spider: Any): ...
    def call_spider(self, result: Any, request: Any, spider: Any): ...
    def handle_spider_error(self, _failure: Any, request: Any, response: Any, spider: Any) -> None: ...
    def handle_spider_output(self, result: Any, request: Any, response: Any, spider: Any): ...
